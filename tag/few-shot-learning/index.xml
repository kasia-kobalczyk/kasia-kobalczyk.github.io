<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>few-shot learning | Katarzyna (Kasia) Kobalczyk</title><link>https://kaasiak.github.io/kasia-kobalczyk/tag/few-shot-learning/</link><atom:link href="https://kaasiak.github.io/kasia-kobalczyk/tag/few-shot-learning/index.xml" rel="self" type="application/rss+xml"/><description>few-shot learning</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 22 Sep 2023 00:00:00 +0000</lastBuildDate><image><url>https://kaasiak.github.io/kasia-kobalczyk/media/icon_hu657cd6d5c75f57c23416a235dc5083f6_34177_512x512_fill_lanczos_center_3.png</url><title>few-shot learning</title><link>https://kaasiak.github.io/kasia-kobalczyk/tag/few-shot-learning/</link></image><item><title>Tabular Few-Shot Generalization Across Heterogenous Feature Spaces</title><link>https://kaasiak.github.io/kasia-kobalczyk/publications/articles/flat/</link><pubDate>Fri, 22 Sep 2023 00:00:00 +0000</pubDate><guid>https://kaasiak.github.io/kasia-kobalczyk/publications/articles/flat/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="imgage" srcset="
/kasia-kobalczyk/publications/articles/flat/FLAT_diagram_hu70fa20c8d5553d07968fe95a2b5925cb_425601_aed6b3ecf7331f9d456523c49fd96ed2.webp 400w,
/kasia-kobalczyk/publications/articles/flat/FLAT_diagram_hu70fa20c8d5553d07968fe95a2b5925cb_425601_3021d259bbeae544d296ffd92998cb85.webp 760w,
/kasia-kobalczyk/publications/articles/flat/FLAT_diagram_hu70fa20c8d5553d07968fe95a2b5925cb_425601_1200x1200_fit_q100_h2_lanczos.webp 1200w"
src="https://kaasiak.github.io/kasia-kobalczyk/kasia-kobalczyk/publications/articles/flat/FLAT_diagram_hu70fa20c8d5553d07968fe95a2b5925cb_425601_aed6b3ecf7331f9d456523c49fd96ed2.webp"
width="760"
height="353"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
Despite the prevalence of tabular datasets, learning with just a few labelled examples remains an under-explored area of research. Existing few-shot learning methods are not directly applicable to tabular datasets due to the variation in the relationships between the columns, their underlying meanings, and their permutational invariance. To address these challenges, we propose FLATâ€”the first solution for the generalized problem of tabular few-shot learning, including the critical aspect of knowledge sharing between datasets with heterogenous sets of columns. Using a Dataset2Vec-inspired encoder, FLAT learns a low-dimensional embedding space of tabular datasets and their individual columns that captures the key characteristics of datasets; this enables knowledge transfer and generalization to previously unseen datasets. Based on the embedding of a new dataset, a decoder network generates the parameters of the predictive target network. To handle the varying number of features, their permutational invariance and structural relationship, we implement the target network as a Graph Attention Network. Using a collection of datasets from the UCI Machine Learning Repository, we demonstrate successful generalization to different tabular datasets and a considerable improvement over existing baselines.&lt;/p></description></item></channel></rss>